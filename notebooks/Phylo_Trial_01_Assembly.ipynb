{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Salix* and *Populus* sequence capture: Assembly and Gene Trees\n",
    "\n",
    "Brian J. Sanderson\n",
    "\n",
    "Last updated: 7 May 2020\n",
    "\n",
    "Required programs: [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic), [HybPiper](https://github.com/mossmatters/HybPiper), [mafft](https://mafft.cbrc.jp/alignment/software/), [pal2nal](http://www.bork.embl.de/pal2nal/), [trimal](http://trimal.cgenomics.org/), [RAxML](https://cme.h-its.org/exelixis/software.html)\n",
    "\n",
    "---\n",
    "\n",
    "This analysis notebook describes the assembly of gene sequences and estimation of gene trees from a trial set of three *Populus* and three *Salix* species using our targeteds seqeunce capture array. Included below are a number of HPCC submission scripts. I include these here because when I first started working on this project it took some time for me to adapt existing pipelines I found to work on an HPCC. And so, even though having in-line submission scripts is not the most \"readable\" I am hoping it will help save someone else time in the future.\n",
    "\n",
    "## Trim and QC Reads\n",
    "\n",
    "1. Run Trimmomatic to trim low quality and short reads\n",
    "\n",
    "   **note** files.txt contains just the prefixes of each pair of read files in the raw/ directory\n",
    "\n",
    "```bash\n",
    "parallel --eta --gnu -j 20 \"java -jar ~/bin/Trimmomatic-0.36/trimmomatic-0.36.jar \\\n",
    "                            PE -phred33 \\\n",
    "                            raw/{}_L001_R1_001.fastq \\\n",
    "                            raw/{}_L001_R2_001.fastq \\\n",
    "                            trimmed/{}_R1_paired.fastq \\\n",
    "                            trimmed/{}_R1_unpaired.fastq \\\n",
    "                            trimmed/{}_R2_paired.fastq \\\n",
    "                            trimmed/{}_R2_unpaired.fastq \\\n",
    "                            ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 \\\n",
    "                            LEADING:3 \\\n",
    "                            TRAILING:3 \\\n",
    "                            SLIDINGWINDOW:4:15 \\\n",
    "                            MINLEN:36\" :::: files.txt\n",
    "```\n",
    "\n",
    "2. Run FASTQC on the trimmed files, and compare with raw\n",
    "\n",
    "```bash\n",
    "parallel --gnu --eta --load 80% --j 20 --noswap fastqc -o ${OUTPUT_DIR} {} ::: ${RAW_FASTQ_DIR}/*.fastq\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare metadata files\n",
    "\n",
    "### Target baits file\n",
    "The file ```phyloTargets.fasta``` is simply the 1,219 sequences that represent the targets sequences from the *S. purpurea* reference genome onto which we want to map our sequence capture (or WGS) reads. This includes the 972 genes for which we designed target baits, as well as 247 genes that are paralogous to genes in the bait targets but for which we were not able to design baits. We include both to ideally seperate reads from the paralogous copies in the mapping and assembly steps. **Note**: the names have a prefix \"Sapur-\" because Hybpiper expects gene names in this format.\n",
    "\n",
    "### A list of gene names\n",
    "The file ```genenames.txt``` contains the name of each of the 1,219 genes. **Note**: the names have a prefix \"Sapur-\" because Hybpiper expects gene names in this format.\n",
    "### A list of sample names and FASTQ files\n",
    "\n",
    "The file ```filelist.txt``` contains the names and prefixes for all of the libaries. For each library there are three lines, one that is the prefix for naming the directories (and I hope the labels on all downstream applications), and two that reference the file names.\n",
    "\n",
    "The file ```namelist.txt``` contains just the names of each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble gene sequences with HybPiper\n",
    "\n",
    "I have adapted much of this pipeline from both the [HybPiper tutorial](https://github.com/mossmatters/HybPiper/wiki) as well as [the notes from a workshop](https://github.com/mossmatters/KewHybSeqWorkshop) Matt Johnson gave at Kew. \n",
    "\n",
    "HybPiper uses GNU parallel in order to parallelize jobs. The following batch scripts are all run on the HPCC at Texas Tech University. These scripts are provided as examples for how to run this pipeline on an HPCC, but may need to be adapted to work in different submission queue systems.\n",
    "\n",
    "For readability I have replaced absolute paths with ```${WORK_DIR}``` and ```${SCRATCH_DIR}``` in these scripts. It is strongly recommended that HybPiper outputs to a scratch drive, because it creates an incredibly large number of temporary files.\n",
    "\n",
    "```bash\n",
    "#!/bin/sh\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -t 1-39:3\n",
    "#$ -S /bin/bash\n",
    "#$ -N phyloTrial\n",
    "#$ -o ${WORK_DIR}/log/01/$JOB_NAME.o$JOB_ID.$TASK_ID\n",
    "#$ -e ${WORK_DIR}/log/01/$JOB_NAME.e$JOB_ID.$TASK_ID\n",
    "#$ -q omni\n",
    "#$ -pe sm 36\n",
    "#$ -P quanah\n",
    "\n",
    "# This code block uses the SGE_TASK_ID number (e.g. 1 for the first job in the task array)\n",
    "# to read the lines from filelist.txt to associate the sample names with the correct\n",
    "# FASTQ files as the variables $prefix, $pair1, and $pair2 below\n",
    "\n",
    "prefixNum=\"$SGE_TASK_ID\"\n",
    "prefixNumP=\"$prefixNum\"p\n",
    "pair1Num=$(($prefixNum + 1))\n",
    "pair1NumP=\"$pair1Num\"p\n",
    "pair2Num=$(($pair1Num + 1))\n",
    "pair2NumP=\"$pair2Num\"p\n",
    "prefix=`sed -n \"$prefixNumP\" filelist.txt`\n",
    "pair1=`sed -n \"$pair1NumP\" filelist.txt`\n",
    "pair2=`sed -n \"$pair2NumP\" filelist.txt`\n",
    "\n",
    "${WORK_DIR}/.bin/HybPiper/reads_first.py \\\n",
    "    -b ${WORK_DIR}/phyloTargets.fasta \\\n",
    "    -r ${SCRATCH_DIR}/reads/$pair1 /lustre/scratch/briasand/phylo/reads/$pair2 \\\n",
    "    --prefix ${SCRATCH_DIR}/$prefix \\\n",
    "    --bwa \\\n",
    "    --cpu 36\n",
    "\n",
    "python ${WORK_DIR}/.bin/HybPiper/cleanup.py ${SCRATCH_DIR}/$prefix\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the actual sequences \n",
    "\n",
    "Now that the gene and intron sequences have been assembled by HybPiper, we want to move the actual sequence files from the temporary scratch space, to a more stable location on ```${WORK_DIR}```\n",
    "\n",
    "```bash\n",
    "#!/bin/sh\n",
    "#$ -V\n",
    "#$ -wd ${SCRATCH_DIR}\n",
    "#$ -S /bin/bash\n",
    "#$ -N phyloTrial-postHyb\n",
    "#$ -o ${WORK_DIR}/log/03/$JOB_NAME.o$JOB_ID\n",
    "#$ -e ${WORK_DIR}/log/03/$JOB_NAME.e$JOB_ID\n",
    "#$ -q omni\n",
    "#$ -pe sm 1\n",
    "#$ -P quanah\n",
    "\n",
    "python ${WORK_DIR}/.bin/HybPiper/get_seq_lengths.py ${WORK_DIR}/phyloTargets.fasta ${WORK_DIR}/namelist.txt dna > ${WORK_DIR}/gene_lengths.txt\n",
    "\n",
    "python ${WORK_DIR}/.bin/HybPiper/hybpiper_stats.py ${WORK_DIR}/gene_lengths.txt ${WORK_DIR}/namelist.txt > ${WORK_DIR}/phylo_stats.txt\n",
    "\n",
    "python ${WORK_DIR}/.bin/HybPiper/retrieve_sequences.py ${WORK_DIR}/phyloTargets.fasta . dna\n",
    "mv *.FNA ${WORK_DIR}/FNA/\n",
    "\n",
    "python ${WORK_DIR}/.bin/HybPiper/retrieve_sequences.py ${WORK_DIR}/phyloTargets.fasta . aa\n",
    "mv *.FAA ${WORK_DIR}/phyloTrial/FAA/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify genes with potential paralogs\n",
    "\n",
    "HybPiper identifies genes that have multiple competing assemblies that are around the same length as the primary assembly as potentially having paralogs. The following is adapted from the [HybPiper paralog tutorial](https://github.com/mossmatters/HybPiper/wiki/Paralogs).\n",
    "\n",
    "```bash\n",
    "#!/bin/sh\n",
    "#$ -V\n",
    "#$ -wd ${SCRATCH_DIR}\n",
    "#$ -S /bin/bash\n",
    "#$ -N phyloTrial-prepParalogs\n",
    "#$ -o ${WORK_DIR}/log/04/$JOB_NAME.o$JOB_ID\n",
    "#$ -e ${WORK_DIR}/log/04/$JOB_NAME.e$JOB_ID\n",
    "#$ -q omni\n",
    "#$ -pe sm 1\n",
    "#$ -P quanah\n",
    "\n",
    "while read i; do echo $i;\n",
    "    python ${WORK_DIR}/.bin/HybPiper/paralog_investigator.py $i;\n",
    "done < ${WORK_DIR}/namelist.txt\n",
    "\n",
    "```\n",
    "\n",
    "The stderr file that is generated contains a list of all of the genes with the counts of paralog warnings in them. It needs to be processed in order to be useful. It is named in part by the job number on the HPCC, so it named something like ```log/04/phylo-prepParalogs.e######```. Use the following code to generate a list of the unique genes with paralog warnings:\n",
    "\n",
    "```bash\n",
    "cat log/04/phylo-prepParalogs.e220513 | cut -f 5 -d ' ' | sort | uniq > genesWithParalogs.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phylogenetic analysis\n",
    "\n",
    "### Prepare the sequence files for RAxML\n",
    "\n",
    "This script will:\n",
    "1. Convert the **\\*** characters into **X** characters for stop codons\n",
    "2. Prepare sequence alignments on the amino acid sequences using mafft\n",
    "3. Convert the aligned amino acid sequences to codon-aligned nucleotide sequences using pal2nal\n",
    "4. Trim the codon-aligned nucleotide sequences using trimal\n",
    "\n",
    "```bash\n",
    "#!/bin/sh\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -S /bin/bash\n",
    "#$ -N phyloTrial-prepTreeFiles\n",
    "#$ -t 1-1219:1\n",
    "#$ -o ${WORK_DIR}/log/06/$JOB_NAME.o$JOB_ID.$TASK_ID\n",
    "#$ -e ${WORK_DIR}/log/06/$JOB_NAME.e$JOB_ID.$TASK_ID\n",
    "#$ -q omni\n",
    "#$ -pe sm 1\n",
    "#$ -P quanah\n",
    "\n",
    "prefixNum=$(SGE_TASK_ID)\n",
    "prefixNumP=$(prefixNum)p\n",
    "prefix=`sed -n $(prefixNumP) genenames.txt`\n",
    "\n",
    "sed -i 's/*/X/g' FAA/$(prefix).FAA\n",
    "\n",
    "mafft --localpair --maxiterate 1000 FAA/$(prefix).FAA > aligned/$(prefix).aligned.FAA\n",
    "\n",
    "${WORK_DIR}/.bin/pal2nal.v14/pal2nal.pl -output fasta aligned/$(prefix).aligned.FAA FNA/$(prefix).FNA > inframe/$(prefix).inframe.FNA\n",
    "\n",
    "trimal -gt 0.5 -in inframe/$(prefix).inframe.FNA -out trimmed/$(prefix).trimmed.FNA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create gene trees with RAxML\n",
    "\n",
    "This script uses RAxML to create gene trees with 250 bootstrap replicates for all 972 genes\n",
    "\n",
    "```bash\n",
    "#!/bin/sh\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -S /bin/bash\n",
    "#$ -N phyloTrial-makeTrees\n",
    "#$ -t 1-1219:1\n",
    "#$ -o ${WORK_DIR}/log/07/$JOB_NAME.o$JOB_ID.$TASK_ID\n",
    "#$ -e ${WORK_DIR}/log/07/$JOB_NAME.e$JOB_ID.$TASK_ID\n",
    "#$ -q omni\n",
    "#$ -pe sm 1\n",
    "#$ -P quanah\n",
    "\n",
    "prefixNum=$(SGE_TASK_ID)\n",
    "prefixNumP=$(prefixNum)p\n",
    "prefix=`sed -n $(prefixNumP) genenames.txt`\n",
    "\n",
    "\n",
    "\n",
    "raxmlHPC -m GTRGAMMA -p 12345 -# 20 -s trimmed/$(prefix).trimmed.FNA -n $(prefix)\n",
    "mv RAxML*$(prefix)* RAxML/bestTree/\n",
    "\n",
    "raxmlHPC -m GTRGAMMA -p 12345 -b 12345 -# 250 -s trimmed/$(prefix).trimmed.FNA -n $(prefix)\n",
    "mv RAxML*($prefix)* RAxML/bootstrap/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
